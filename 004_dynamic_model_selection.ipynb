{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "238751a3-bc96-4b0a-9821-ec722d92e56d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# LangChain 1.0 Dynamic Model Selection\n",
    "\n",
    "Ref:\n",
    "https://docs.langchain.com/oss/python/langchain/agents#dynamic-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "357ccaea-86f9-47cf-affe-99fc4c1ecdc4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U langchain>=1.0.0 langchain_openai>=1.0.0 mlflow\n",
    "\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ac46ba61-2705-4f4d-83d1-afded2a7fe17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## モデルとの接続"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1766dac6-7da0-4134-b53d-f09a395d0478",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "import mlflow\n",
    "\n",
    "\n",
    "mlflow.langchain.autolog()\n",
    "\n",
    "creds = mlflow.utils.databricks_utils.get_databricks_host_creds()\n",
    "llm_config = {\"api_key\": creds.token, \"base_url\": creds.host + \"/serving-endpoints\"}\n",
    "\n",
    "# 2種のモデルを準備\n",
    "basic_model = init_chat_model(\"openai:databricks-gpt-oss-20b\", **llm_config)\n",
    "advanced_model = init_chat_model(\"openai:databricks-gpt-oss-120b\", **llm_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1b24e175-2954-499e-82f1-1f33f7c765ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## エージェントの作成と実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "860b03d3-41f9-4d75-b9ec-3dec8e047563",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse\n",
    "\n",
    "@wrap_model_call\n",
    "def dynamic_model_selection(request: ModelRequest, handler) -> ModelResponse:\n",
    "    \"\"\"会話の複雑さに基づいてモデルを選択します。\"\"\"\n",
    "    message_count = len(request.state[\"messages\"])\n",
    "\n",
    "    if message_count > 3:\n",
    "        # 処理履歴が長い場合は高度なモデルを使用する\n",
    "        model = advanced_model\n",
    "    else:\n",
    "        model = basic_model\n",
    "\n",
    "    request.model = model\n",
    "    return handler(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ca9e07b-3956-4374-8762-4736b807ebfb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from pprint import pprint\n",
    "\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"指定した都市の天気を取得します。\"\"\"\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=basic_model,\n",
    "    tools=[get_weather],\n",
    "    middleware=[dynamic_model_selection],\n",
    ")\n",
    "\n",
    "print(\"---- simple ---\")\n",
    "input = {\"messages\": [{\"role\": \"user\", \"content\": \"SFの天気は？\"}]}\n",
    "result = agent.invoke(input)\n",
    "print(\"answer:\", result[\"messages\"][-1].content)\n",
    "print(\"model:\", result[\"messages\"][-1].response_metadata[\"model_name\"])\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"---- complex ---\")\n",
    "input = {\"messages\": [{\"role\": \"user\", \"content\": \"東京・大阪・福岡の天気を教えてください。\"}]}\n",
    "result = agent.invoke(input)\n",
    "print(\"answer:\", result[\"messages\"][-1].content)\n",
    "print(\"model:\", result[\"messages\"][-1].response_metadata[\"model_name\"])\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "004_dynamic_model_selection",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
