{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "238751a3-bc96-4b0a-9821-ec722d92e56d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# LangChain 1.0 Initialize a model\n",
    "\n",
    "Ref:\n",
    "\n",
    "- https://docs.langchain.com/oss/python/langchain/models#initialize-a-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "357ccaea-86f9-47cf-affe-99fc4c1ecdc4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U langchain>=1.0.0 langchain_openai>=1.0.0 mlflow deepagents tavily-python\n",
    "\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ac46ba61-2705-4f4d-83d1-afded2a7fe17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## モデルとの接続"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1766dac6-7da0-4134-b53d-f09a395d0478",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "import mlflow\n",
    "import os\n",
    "\n",
    "mlflow.langchain.autolog()\n",
    "\n",
    "creds = mlflow.utils.databricks_utils.get_databricks_host_creds()\n",
    "llm_config = {\"api_key\": creds.token, \"base_url\":creds.host + \"/serving-endpoints\"}\n",
    "model = init_chat_model(\n",
    "    \"openai:databricks-qwen3-next-80b-a3b-instruct\", **llm_config\n",
    ")\n",
    "\n",
    "# model.invoke(\"Hello\")\n",
    "\n",
    "# 以下のように環境変数設定でもできる\n",
    "# os.environ[\"OPENAI_API_KEY\"] = creds.token\n",
    "# os.environ[\"OPENAI_BASE_URL\"] = creds.host + \"/serving-endpoints\"\n",
    "\n",
    "# model = init_chat_model(\"openai:databricks-gpt-oss-20b\")\n",
    "# model.invoke(\"Hello\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c1d33e7-1b51-432b-8321-52a9b2fc981f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Literal\n",
    "from tavily import TavilyClient\n",
    "from deepagents import create_deep_agent\n",
    "from langchain.agents.middleware import ModelFallbackMiddleware\n",
    "\n",
    "tavily_client = TavilyClient(api_key=dbutils.secrets.get(scope=\"tavily\", key=\"api_key\"))\n",
    "\n",
    "def internet_search(\n",
    "    query: str,\n",
    "    max_results: int = 5,\n",
    "    topic: Literal[\"general\", \"news\", \"finance\"] = \"general\",\n",
    "    include_raw_content: bool = False,\n",
    "):\n",
    "    \"\"\"Run a web search\"\"\"\n",
    "    return tavily_client.search(\n",
    "        query,\n",
    "        max_results=max_results,\n",
    "        include_raw_content=include_raw_content,\n",
    "        topic=topic,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36a15720-b47a-4430-a7c5-7f0e0f165c89",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# System prompt to steer the agent to be an expert researcher\n",
    "research_instructions = \"\"\"You are an expert researcher. Your job is to conduct thorough research and then write a polished report.\n",
    "\n",
    "You have access to an internet search tool as your primary means of gathering information.\n",
    "\n",
    "## `internet_search`\n",
    "\n",
    "Use this to run an internet search for a given query. You can specify the max number of results to return, the topic, and whether raw content should be included.\n",
    "\"\"\"\n",
    "\n",
    "agent = create_deep_agent(\n",
    "    model=model,\n",
    "    tools=[internet_search],\n",
    "    system_prompt=research_instructions,\n",
    "    middleware=[\n",
    "        ModelFallbackMiddleware(\n",
    "            init_chat_model(\"openai:databricks-gemma-3-12b\", **llm_config),\n",
    "            init_chat_model(\"openai:databricks-gpt-oss-120b\", **llm_config),\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a417aae6-d6de-4f12-864e-cbc244912408",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"What is langgraph?\"}]})\n",
    "\n",
    "# Print the agent's response\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7c583a50-2f56-40c8-859c-2564334f3a88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## DeepResearch Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d85098aa-82b1-4c65-b24b-fbdcaf9d6fce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Literal\n",
    "\n",
    "fallback_middleware = ModelFallbackMiddleware(\n",
    "    init_chat_model(\"openai:databricks-gemma-3-12b\", **llm_config),\n",
    "    init_chat_model(\"openai:databricks-gpt-oss-120b\", **llm_config),\n",
    ")\n",
    "\n",
    "sub_research_prompt = \"\"\"You are a dedicated researcher. Your job is to conduct research based on the users questions.\n",
    "\n",
    "Conduct thorough research and then reply to the user with a detailed answer to their question\n",
    "\n",
    "only your FINAL answer will be passed on to the user. They will have NO knowledge of anything except your final message, so your final report should be your final message!\"\"\"\n",
    "\n",
    "research_sub_agent = {\n",
    "    \"name\": \"research-agent\",\n",
    "    \"description\": \"Used to research more in depth questions. Only give this researcher one topic at a time. Do not pass multiple sub questions to this researcher. Instead, you should break down a large topic into the necessary components, and then call multiple research agents in parallel, one for each sub question.\",\n",
    "    \"system_prompt\": sub_research_prompt,\n",
    "    \"tools\": [internet_search],\n",
    "    \"model\": init_chat_model(\"openai:databricks-gpt-oss-120b\", **llm_config),\n",
    "    \"middleware\": [fallback_middleware],\n",
    "}\n",
    "\n",
    "sub_critique_prompt = \"\"\"You are a dedicated editor. You are being tasked to critique a report.\n",
    "\n",
    "You can find the report at `final_report.md`.\n",
    "\n",
    "You can find the question/topic for this report at `question.txt`.\n",
    "\n",
    "The user may ask for specific areas to critique the report in. Respond to the user with a detailed critique of the report. Things that could be improved.\n",
    "\n",
    "You can use the search tool to search for information, if that will help you critique the report\n",
    "\n",
    "Do not write to the `final_report.md` yourself.\n",
    "\n",
    "Things to check:\n",
    "- Check that each section is appropriately named\n",
    "- Check that the report is written as you would find in an essay or a textbook - it should be text heavy, do not let it just be a list of bullet points!\n",
    "- Check that the report is comprehensive. If any paragraphs or sections are short, or missing important details, point it out.\n",
    "- Check that the article covers key areas of the industry, ensures overall understanding, and does not omit important parts.\n",
    "- Check that the article deeply analyzes causes, impacts, and trends, providing valuable insights\n",
    "- Check that the article closely follows the research topic and directly answers questions\n",
    "- Check that the article has a clear structure, fluent language, and is easy to understand.\n",
    "\"\"\"\n",
    "\n",
    "critique_sub_agent = {\n",
    "    \"name\": \"critique-agent\",\n",
    "    \"description\": \"Used to critique the final report. Give this agent some information about how you want it to critique the report.\",\n",
    "    \"system_prompt\": sub_critique_prompt,\n",
    "    \"model\": init_chat_model(\"openai:databricks-gpt-oss-120b\", **llm_config),\n",
    "    \"middleware\": [fallback_middleware],\n",
    "}\n",
    "\n",
    "\n",
    "# Prompt prefix to steer the agent to be an expert researcher\n",
    "research_instructions = \"\"\"You are an expert researcher. Your job is to conduct thorough research, and then write a polished report.\n",
    "\n",
    "The first thing you should do is to write the original user question to `question.txt` so you have a record of it.\n",
    "\n",
    "Use the research-agent to conduct deep research. It will respond to your questions/topics with a detailed answer.\n",
    "\n",
    "When you think you enough information to write a final report, write it to `final_report.md`\n",
    "\n",
    "You can call the critique-agent to get a critique of the final report. After that (if needed) you can do more research and edit the `final_report.md`\n",
    "You can do this however many times you want until are you satisfied with the result.\n",
    "\n",
    "Only edit the file once at a time (if you call this tool in parallel, there may be conflicts).\n",
    "\n",
    "Here are instructions for writing the final report:\n",
    "\n",
    "<report_instructions>\n",
    "\n",
    "CRITICAL: Make sure the answer is written in the same language as the human messages! If you make a todo plan - you should note in the plan what language the report should be in so you dont forget!\n",
    "Note: the language the report should be in is the language the QUESTION is in, not the language/country that the question is ABOUT.\n",
    "\n",
    "Please create a detailed answer to the overall research brief that:\n",
    "1. Is well-organized with proper headings (# for title, ## for sections, ### for subsections)\n",
    "2. Includes specific facts and insights from the research\n",
    "3. References relevant sources using [Title](URL) format\n",
    "4. Provides a balanced, thorough analysis. Be as comprehensive as possible, and include all information that is relevant to the overall research question. People are using you for deep research and will expect detailed, comprehensive answers.\n",
    "5. Includes a \"Sources\" section at the end with all referenced links\n",
    "\n",
    "You can structure your report in a number of different ways. Here are some examples:\n",
    "\n",
    "To answer a question that asks you to compare two things, you might structure your report like this:\n",
    "1/ intro\n",
    "2/ overview of topic A\n",
    "3/ overview of topic B\n",
    "4/ comparison between A and B\n",
    "5/ conclusion\n",
    "\n",
    "To answer a question that asks you to return a list of things, you might only need a single section which is the entire list.\n",
    "1/ list of things or table of things\n",
    "Or, you could choose to make each item in the list a separate section in the report. When asked for lists, you don't need an introduction or conclusion.\n",
    "1/ item 1\n",
    "2/ item 2\n",
    "3/ item 3\n",
    "\n",
    "To answer a question that asks you to summarize a topic, give a report, or give an overview, you might structure your report like this:\n",
    "1/ overview of topic\n",
    "2/ concept 1\n",
    "3/ concept 2\n",
    "4/ concept 3\n",
    "5/ conclusion\n",
    "\n",
    "If you think you can answer the question with a single section, you can do that too!\n",
    "1/ answer\n",
    "\n",
    "REMEMBER: Section is a VERY fluid and loose concept. You can structure your report however you think is best, including in ways that are not listed above!\n",
    "Make sure that your sections are cohesive, and make sense for the reader.\n",
    "\n",
    "For each section of the report, do the following:\n",
    "- Use simple, clear language\n",
    "- Use ## for section title (Markdown format) for each section of the report\n",
    "- Do NOT ever refer to yourself as the writer of the report. This should be a professional report without any self-referential language. \n",
    "- Do not say what you are doing in the report. Just write the report without any commentary from yourself.\n",
    "- Each section should be as long as necessary to deeply answer the question with the information you have gathered. It is expected that sections will be fairly long and verbose. You are writing a deep research report, and users will expect a thorough answer.\n",
    "- Use bullet points to list out information when appropriate, but by default, write in paragraph form.\n",
    "\n",
    "REMEMBER:\n",
    "The brief and research may be in English, but you need to translate this information to the right language when writing the final answer.\n",
    "Make sure the final answer report is in the SAME language as the human messages in the message history.\n",
    "\n",
    "Format the report in clear markdown with proper structure and include source references where appropriate.\n",
    "\n",
    "<Citation Rules>\n",
    "- Assign each unique URL a single citation number in your text\n",
    "- End with ### Sources that lists each source with corresponding numbers\n",
    "- IMPORTANT: Number sources sequentially without gaps (1,2,3,4...) in the final list regardless of which sources you choose\n",
    "- Each source should be a separate line item in a list, so that in markdown it is rendered as a list.\n",
    "- Example format:\n",
    "  [1] Source Title: URL\n",
    "  [2] Source Title: URL\n",
    "- Citations are extremely important. Make sure to include these, and pay a lot of attention to getting these right. Users will often use these citations to look into more information.\n",
    "</Citation Rules>\n",
    "</report_instructions>\n",
    "\n",
    "You have access to a few tools.\n",
    "\n",
    "## `internet_search`\n",
    "\n",
    "Use this to run an internet search for a given query. You can specify the number of results, the topic, and whether raw content should be included.\n",
    "\"\"\"\n",
    "\n",
    "# Create the agent\n",
    "agent = create_deep_agent(\n",
    "    model=model,\n",
    "    tools=[internet_search],\n",
    "    system_prompt=research_instructions,\n",
    "    subagents=[critique_sub_agent, research_sub_agent],\n",
    "    middleware=[\n",
    "        ModelFallbackMiddleware(\n",
    "            init_chat_model(\"openai:databricks-gemma-3-12b\", **llm_config),\n",
    "            init_chat_model(\"openai:databricks-gpt-oss-120b\", **llm_config),\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7b92977-4827-42b6-aaed-8d8aa55d608c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9adb61e-24fb-46a9-b39b-ace046820256",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"LangChain 1.0で追加された機能や従来から追加された特性について解説してください。\"}]})\n",
    "\n",
    "# Print the agent's response\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17ae21c4-4d35-426d-9a86-cbe58668c09b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for k in result[\"files\"].keys():\n",
    "    print(k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "939ab0b4-0697-4c32-8ed1-ab7a1342e8c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\".join(result[\"files\"][\"/large_tool_results/call_775b5282-c585-4ef8-92df-150aca3f2af4\"][\"content\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2314e4c-a879-46d2-b6db-a86f48853ebd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# /memories/langgraph_summary.md\n",
    "print(\"\\n\".join(result[\"files\"][\"/memories/langgraph_summary.md\"][\"content\"]))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "010_deepagents",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
